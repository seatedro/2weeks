{
  "id": "neural_network_basics",
  "title": "Introduction to Neural Networks",
  "timeEstimate": "4 hours",
  "sections": [
    {
      "type": "section",
      "title": "Understanding Neural Networks",
      "content": "# Introduction to Neural Networks\n\nNeural networks are powerful computing systems inspired by the human brain. Let's break down the core concepts:\n\n## 1. The Basic Building Block: Neurons\n\n- Single neurons are simple computational units\n- Each neuron:\n  * Receives multiple inputs\n  * Applies weights to these inputs\n  * Adds a bias term\n  * Processes through an activation function\n  * Produces an output\n\n## 2. How Neural Networks Learn\n\n- Networks learn by adjusting weights and biases\n- Learning process:\n  * Forward pass: Make predictions\n  * Calculate error\n  * Backward pass: Update weights\n  * Repeat until performance improves\n\n## 3. Key Components\n\n- Weights: Strength of connections between neurons\n- Biases: Offset values that control activation\n- Activation Functions: Add non-linearity to the network\n- Loss Functions: Measure prediction error\n\n## 4. From Single Neurons to Networks\n\n- Multiple neurons form layers\n- Layers stack to form deep networks\n- Information flows through the network\n- Each layer transforms the data in useful ways",
      "checkpoints": [
        {
          "id": "basics_understanding",
          "title": "Core Concepts",
          "items": [
            {
              "id": "single_neuron",
              "type": "concept",
              "title": "Single Neuron Implementation",
              "content": "Learn to implement a basic neuron in PyTorch.",
              "mastery_protocols": [
                {
                  "task": "Create a single neuron",
                  "difficulty": "beginner",
                  "example": {
                    "problem": "Implement a single neuron with 3 inputs",
                    "solution": {
                      "code": "import torch\nimport torch.nn as nn\n\nclass SingleNeuron(nn.Module):\n    def __init__(self, input_size=3):\n        super().__init__()\n        # One neuron with input_size inputs\n        self.neuron = nn.Linear(input_size, 1)\n        \n    def forward(self, x):\n        # Apply the neuron and an activation function\n        return torch.relu(self.neuron(x))\n\n# Create and test the neuron\nneuron = SingleNeuron()\ninputs = torch.randn(4, 3)  # 4 samples, 3 features each\noutput = neuron(inputs)\nprint(output.shape)  # torch.Size([4, 1])",
                      "explanation": "This implements a single neuron that takes 3 inputs, applies weights and bias, and uses ReLU activation. The neuron can process multiple samples at once (batch processing).",
                      "expected_output": "tensor with shape [4, 1] containing the neuron's output for 4 input samples"
                    }
                  }
                }
              ]
            },
            {
              "id": "basic_network",
              "type": "concept",
              "title": "Simple Neural Network",
              "content": "Build your first neural network with multiple neurons.",
              "mastery_protocols": [
                {
                  "task": "Create a simple two-layer network",
                  "difficulty": "beginner",
                  "example": {
                    "problem": "Build a network with one hidden layer",
                    "solution": {
                      "code": "class SimpleNetwork(nn.Module):\n    def __init__(self, input_size=3, hidden_size=4, output_size=2):\n        super().__init__()\n        # First layer\n        self.layer1 = nn.Linear(input_size, hidden_size)\n        # Output layer\n        self.layer2 = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, x):\n        # Pass through first layer with ReLU\n        x = torch.relu(self.layer1(x))\n        # Pass through output layer\n        return self.layer2(x)\n\n# Create and test the network\nnet = SimpleNetwork()\ninputs = torch.randn(4, 3)  # 4 samples, 3 features each\noutput = net(inputs)\nprint(output.shape)  # torch.Size([4, 2])",
                      "explanation": "Implements a small network with an input layer (3 neurons), hidden layer (4 neurons), and output layer (2 neurons). ReLU activation adds non-linearity between layers.",
                      "expected_output": "tensor with shape [4, 2] containing network predictions for 4 input samples"
                    }
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "code",
      "title": "Training Your First Network",
      "content": "Learn how to train a neural network from scratch.",
      "training_simulations": [
        {
          "id": "first_training",
          "title": "Basic Training Loop",
          "difficulty": "beginner",
          "mission": "Implement a complete training loop for a simple neural network",
          "content": "# Here's the basic structure\nmodel = SimpleNetwork()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# TODO: Implement training loop\n",
          "solution_sequence": "# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    # Forward pass\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    \n    # Backward pass and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Print progress\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')",
          "solution_explanation": "This implements a basic training loop that:\n1. Makes predictions (forward pass)\n2. Calculates loss\n3. Computes gradients (backward pass)\n4. Updates weights (optimization step)\n5. Monitors progress"
        }
      ],
      "projects": [
        {
          "id": "binary_classifier",
          "title": "Simple Binary Classifier",
          "difficulty": "beginner",
          "description": "Create a neural network to classify points into two categories",
          "checkpoints": [
            {
              "id": "data_prep",
              "title": "Data Preparation",
              "task": "Prepare a simple dataset of points and labels",
              "verification": "Dataset should contain points in 2D space with binary labels"
            },
            {
              "id": "model_creation",
              "title": "Model Creation",
              "task": "Create a neural network for binary classification",
              "verification": "Model should output probabilities using sigmoid activation"
            },
            {
              "id": "training",
              "title": "Model Training",
              "task": "Train the model using binary cross-entropy loss",
              "verification": "Loss should decrease during training"
            }
          ]
        }
      ]
    }
  ],
  "quick_references": {
    "common_operations": [
      {
        "operation": "Creating a Network",
        "examples": [
          {
            "description": "Simple feedforward network",
            "code": "model = nn.Sequential(\n    nn.Linear(input_size, hidden_size),\n    nn.ReLU(),\n    nn.Linear(hidden_size, output_size)\n)"
          }
        ]
      },
      {
        "operation": "Training a Network",
        "examples": [
          {
            "description": "Basic training step",
            "code": "optimizer.zero_grad()\noutputs = model(inputs)\nloss = criterion(outputs, targets)\nloss.backward()\noptimizer.step()"
          }
        ]
      }
    ],
    "common_errors": [
      {
        "error": "Incorrect input shapes",
        "solution": "Print shapes of inputs and outputs at each step to debug dimensionality issues"
      },
      {
        "error": "Loss not decreasing",
        "solution": "Check learning rate, data normalization, and network architecture"
      }
    ],
    "memory_management": {
      "best_practices": [
        "Clear gradients before each backward pass",
        "Move model and data to same device (CPU/GPU)",
        "Free memory with del when variables are no longer needed"
      ]
    }
  },
  "resources": {
    "official_docs": [
      {
        "title": "PyTorch Basics Tutorial",
        "url": "https://pytorch.org/tutorials/beginner/basics/intro.html",
        "description": "Official PyTorch introduction to tensors and neural networks"
      },
      {
        "title": "PyTorch nn Module Documentation",
        "url": "https://pytorch.org/docs/stable/nn.html",
        "description": "Complete reference for neural network components"
      }
    ],
    "videos": [
      {
        "title": "Neural Networks from Scratch",
        "url": "https://www.youtube.com/watch?v=aircAruvnKk",
        "duration": "19:13",
        "creator": "3Blue1Brown",
        "description": "Visual introduction to neural networks"
      },
      {
        "title": "PyTorch Basics Tutorial",
        "url": "https://www.youtube.com/watch?v=IC0_FRiX-sw",
        "duration": "1:02:43",
        "creator": "Deep Learning with PyTorch",
        "description": "Hands-on introduction to PyTorch basics"
      }
    ],
    "blog_posts": [
      {
        "title": "Understanding Neural Networks",
        "url": "https://towardsdatascience.com/understanding-neural-networks-19020b758230",
        "author": "Towards Data Science",
        "readingTime": "15 mins",
        "difficulty": "beginner",
        "tags": [
          "neural-networks",
          "basics",
          "tutorial"
        ]
      }
    ],
    "research_papers": [
      {
        "title": "Deep Learning",
        "url": "https://www.nature.com/articles/nature14539",
        "authors": [
          "Yann LeCun",
          "Yoshua Bengio",
          "Geoffrey Hinton"
        ],
        "year": 2015,
        "relevantSections": [
          "Basic Concepts",
          "Historical Context",
          "Fundamental Principles"
        ]
      }
    ]
  },
  "security_level": "1",
  "compression": true,
  "backup": true
}
